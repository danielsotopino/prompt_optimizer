#!/usr/bin/env python3
"""
Script de prueba rÃ¡pida para el framework SPO
Ejecuta una optimizaciÃ³n bÃ¡sica sin necesidad de configuraciÃ³n compleja
"""
import asyncio
import os
import sys
from spo_framework import SPOFramework, PromptOptimizationConfig

async def quick_test():
    """Prueba rÃ¡pida del framework"""
    
    # Verificar API key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ Error: Por favor configura tu OPENAI_API_KEY")
        print("Ejecuta: export OPENAI_API_KEY='tu-api-key-aqui'")
        return
    
    print("ğŸš€ Iniciando prueba de optimizaciÃ³n SPO...")
    print("=" * 50)
    
    # ConfiguraciÃ³n de prueba
    config = PromptOptimizationConfig(
        max_iterations=3,  # Solo 3 iteraciones para prueba rÃ¡pida
        optimization_model="gpt-4o-mini",  # Modelo mÃ¡s econÃ³mico
        execution_model="gpt-4o-mini",
        evaluation_model="gpt-4o-mini",
        temperature=0.7
    )
    
    # Datos de prueba
    initial_prompt = """Clasifica el siguiente tÃ­tulo de trabajo en categorÃ­as apropiadas.
Usa el formato: CategorÃ­a - SubcategorÃ­a

TÃ­tulo de trabajo: {job_title}
ClasificaciÃ³n:"""
    
    task_description = "Clasificar tÃ­tulos de trabajo en categorÃ­as significativas"
    
    sample_inputs = [
        "Senior Software Engineer",
        "Data Scientist", 
        "Marketing Manager"
    ]
    
    expected_outputs = [
        "Technology - Software Engineering",
        "Technology - Data Science",
        "Business - Marketing"
    ]
    
    print("ğŸ“ Prompt inicial:")
    print(f"'{initial_prompt}'")
    print("\nğŸ“Š Datos de prueba:")
    for i, (inp, exp) in enumerate(zip(sample_inputs, expected_outputs)):
        print(f"  {i+1}. '{inp}' â†’ '{exp}'")
    
    print("\nğŸ”„ Ejecutando optimizaciÃ³n...")
    
    try:
        # Crear framework y ejecutar optimizaciÃ³n
        framework = SPOFramework(config, api_key)
        
        result = await framework.optimize_prompt(
            initial_prompt=initial_prompt,
            task_description=task_description,
            sample_inputs=sample_inputs,
            expected_outputs=expected_outputs
        )
        
        # Mostrar resultados
        print("\nâœ… Â¡OptimizaciÃ³n completada!")
        print("=" * 50)
        print(f"ğŸ“ˆ PuntuaciÃ³n final: {result.performance_score:.2f}")
        print(f"ğŸ”„ Iteraciones realizadas: {result.iteration}")
        print(f"â±ï¸ Tiempo de ejecuciÃ³n: {result.execution_time:.1f}s")
        
        print(f"\nğŸ“ Prompt optimizado:")
        print("-" * 30)
        print(result.optimized_prompt)
        print("-" * 30)
        
        print(f"\nğŸ’­ RetroalimentaciÃ³n:")
        print(result.feedback)
        
        # Resumen de la optimizaciÃ³n
        summary = framework.get_optimization_summary()
        print(f"\nğŸ“Š Resumen de optimizaciÃ³n:")
        print(f"  â€¢ Mejora total: +{summary['improvement']:.2f}")
        print(f"  â€¢ Tiempo total: {summary['total_time']:.1f}s")
        print(f"  â€¢ Mejor iteraciÃ³n: #{summary['best_iteration']}")
        
        print("\nğŸ‰ Â¡Prueba completada exitosamente!")
        
    except Exception as e:
        print(f"\nâŒ Error durante la optimizaciÃ³n: {str(e)}")
        print("ğŸ’¡ AsegÃºrate de que tu API key sea vÃ¡lida y tengas crÃ©ditos disponibles")

if __name__ == "__main__":
    print("ğŸ¤– Framework SPO - Prueba RÃ¡pida")
    print("AsegÃºrate de haber configurado OPENAI_API_KEY")
    print()
    
    # Ejecutar prueba
    asyncio.run(quick_test())